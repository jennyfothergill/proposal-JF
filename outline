new idea:
# what has been done
<MARTINI, TRAPPE>









reproducibility crisis.\cite{Cummings2019} \cite{Thompson2020} (TRUE paper) poorly documented code and raw data doesn't help. 
instead example workflows with docker containers to build software stack. help make science more accessible and reprodicible.

the one part of coarse graining that is not yet automated is choosing a mapping scheme.
there have been efforts to create mapping schemes for automating the process of deciding which atoms are grouped in a "super-atom" bead. 
As the number of atoms in the fine grain structure increases, the number of possible mappings increase drastically. The number of allowed mappings can be reduced by only allowing those which do not change the symmetry group, then an algorithm can iterate over a graph of all possible mappings the "best" mapping being the one which minimizes the difference between the mapped RDF and velocity autocorrelation function. \cite{Chakraborty2018a}

smile \cite{Weininger} was designed to represent organic molecules in an unambiguous way (similar to IUPAC) but smiles is also readable by a computer.
This makes it a good candidate for specifying a coarse-grain mapping scheme.

# what remains to be done?

# Why should the work be done?
# what specific problems will it solve?

# how will the work be done?
- I will build on existing tools (signac,freud,mbuild,foyer,tim moore's msibi)
- create signac workflow which takes equilibrated atomistic trajectory (maybe checks if it's equilibrated?) maps the CG beads to it, runs IBI, gets tabulated FF, creates larger CG sim, runs it, does backmapping, then could do: RDF, charge transport, diffraction... if this workflow is streamlined--it can be applied to many different compounds allowing for us to compare the analyses between our zoo of compounds.
- maybe the workflow could even involve getting the equilibrated trajectory (atomtyping/fill box/run) with the new hoomd 3 api we could even set decorrelation time as a stop trigger...

# what have you accomplished already? what remains?
- contributed to development of open-source packages: mbuild, foyer, signac, fresnel
 this has helped me learn best software development practices like writing documentation, using version control, writing unit tests, employing CI, fork/pull model, etc. using these tools will help me to me a more efficient developer. It's also helped me to learn how to work as part of a team.
 - created MWE of coarse-graining and backmapping with smiles-- these will need furthertesting as we try them on different compounds but the proof of concept is there.
 - created tutorial examples to help current and future students understand scientific concepts and how to use computational tools
 - created GIXStapose (presented at SciPy2020) an interactive diffraction/structure viewer. This may seem unrelated but we can use diffraction to verify our opv morphologies and compare them to experiment. GIXStapose helps to beeter connect the physical structure with the diffraction pattern.
- started development on UFF repo for foyer. This is an example of how to create a version controlled forcefield which can be automatically applied to a compound. (atom typing is a pain)

#what is the timeline?
#what answers will be immediately forthcoming?
#what additional major research will result?

#will the work involve an outreach component?

#Intellectual merit and broader impacts?







Garbage first pass at abstract--probably just delete.

In order to make the most efficient opvs we need to find the best blend of compounds and the processing conditions that result in the best structure for those compounds. With minor modifcations the number of compounds and the processing conditions can become infinite which makes this an intractable problem for experiment.
by using a simulation pipeline, we can help to streamline the process of determining which opv materials will help to solve the energy crisis
simulation also helps to give us insight into the atomic interaction which drive self assembly.
a complication of this simulation is that the features which are important to the performance of an opv span multiple length scales. The electronic properties are important for light absorption, charge transfer <morehere>
while the bulk morphological properties are important: an exciton needs to be able to find an interface at which to dissociate before it decays through one of its non-radiative processes and one the charges are separated they need to reach an electrode in order to generate current and produce electricity. <interfacial area and connectivity>
"all models are wrong but some are useful" - George Box 1976 
it is not only computationally intractable to try and simulate the electron density of an opv polymer melt on length scales proportional to the exciton dissociation length (~5-10 nm) -- it is the wrong tool for the job. if what we are interested in is the properties of the polymer in the bulk heterojunction then it is wise to abstract away any degrees of freedom which do not directly contribute to the self-assembly of the structure. once a good bulk structure has been achieved these details can be reintegrated much more easily. This is the idea behind a coarse grain model.
my proposal is to develop a coarse-graining pipeline which will simplify the process mapping the coarse grain model onto the structure, parameterizing the forces and backmapping to retrieve atomistic details. 
<electronic structure, quantum > MD atomistic, classical forces> but each atom is represented > CG multiple atoms can be grouped together to form a super atom and then the effective force can be iteratively approximated using Boltzmann inversion (IBI). 
this has already been done-- lots of CG force fields already exist. The martini method <more> 
my idea is to use a systematic language for specifying chemical structure (SMARTS) to automate the bead mapping and backmapping. 
By creating an automation scheme which is understandable and makes chemical sense, we hope to simplify the process of creating and using a coarse-grain model.
we can use this do develop new coarse-grain models and test their efficacy in predicting charge transport.
