new idea:
# what has been done
coarse graining

TraPPE fits CG potentials using vapor-liquid equilibria to improve transferrability across Thermodynamic states\cite{Maerzke2011}


how cg potentials have been obtained




reproducibility crisis.\cite{Cummings2019} \cite{Thompson2020} (TRUE paper) poorly documented code and raw data doesn't help. 
instead example workflows with docker containers to build software stack. help make science more accessible and reprodicible.

the one part of coarse graining that is not yet automated is choosing a mapping scheme or a mapping operator. A mapping operator defines which atoms are grouped into a "super atom" represented by one coarse grain site and an effective potential and where in the site is placed relative to the atom group.
mapping operators are chosen based on desired resolution of the coarse grain system and the information to be extracted. 
A straightforward way to define a mapping operator is to group a set number of heavy atoms (non hydrogen) together--this is the method used in the MARTINI force field. \cite{Marrink2007} In this scheme, four atoms (except rings, which are treated differently) are grouped and the site is classified as polar, non-polar, apolar, or charged depending on the atoms it is composed of. When parameterizing a new molecule you must pick a mapping and thencompare the resulting beads to existing beads--time consuming and error prone.\cite{http://www.cgmartini.nl/index.php/tutorials-general-introduction-gmx5/parametrzining-new-molecule-gmx5} This force field was designed for lipids and has shown to be effective in predicting vesicle formation, membrane protein dynamics, etc.
use chemical intuition--e.g. what parts of the molecule shouldn't be allowed to bend?
there have been efforts to create mapping schemes for automating the process of deciding which atoms are grouped in a "super-atom" bead. 
As the number of atoms in the fine grain structure increases, the number of possible mappings increase drastically. The number of allowed mappings can be reduced by only allowing those which do not change the symmetry group, then an algorithm can iterate over a graph of all possible mappings the "best" mapping being the one which minimizes the difference between the mapped RDF and velocity autocorrelation function. \cite{Chakraborty2018a}
Another mapping scheme uses principle component analysis to choose a mapping scheme for biomolecules that best represents th essential dynamics. \cite{Zhang2008}
\cite{li2020} mapping operators can be automated using a machine learning: clustering methods combined with graph analysis were shown to predict the "expert" mapping chosen using chemical intuition reliably.
In order to probe electrostatic properties, a mapping operator based on the centers of charge is described\cite{Cao2015a}
We do not propose a new automated mapping, but instead a way to make the mapping and backmapping process easier for the user.
Simplified Molecular Input Line Entry System or SMILES \cite{Weininger} was designed to represent organic molecules in an unambiguous way (similar to IUPAC) but in a line-entry system which is also readable by a computer.
This makes it a good candidate for specifying a coarse-grain mapping scheme.The open-source package, Openbabel, allows for a SMILES string to be converted to a chemical structure and vice versa. <cite openbabel,SMILES, SMARTS> SMARTS is similar to SMILES but instead of representing a single molecule unambiguously, it has multiple wildcards which can be used for pattern matching. This pattern matching is also implemented in the Openbabel package. If we know the SMARTS string for any given CG mapping we can map the CG site to it's center of mass or geometric center.
I have developed a minimum working example of how this can be done <cite grits> and then how the atomistic structure can be recovered. It could be fairly straightforward to implement a lookup to check if bead parameters already exist--say for the MARTINI model-- by going through and writing out the SMARTS pattern for each existing bead type. An initial headache that could make parameterizing new compounds for the MARTINI method more foolproof.

# what remains to be done?

# Why should the work be done?
# what specific problems will it solve?

# how will the work be done?
- I will build on existing tools (signac,freud,mbuild,foyer,tim moore's msibi)
- create signac workflow which takes equilibrated atomistic trajectory (maybe checks if it's equilibrated?) maps the CG beads to it, runs IBI, gets tabulated FF, creates larger CG sim, runs it, does backmapping, then could do: RDF, charge transport, diffraction... if this workflow is streamlined--it can be applied to many different compounds allowing for us to compare the analyses between our zoo of compounds.
- maybe the workflow could even involve getting the equilibrated trajectory (atomtyping/fill box/run) with the new hoomd 3 api we could even set decorrelation time as a stop trigger...

# what have you accomplished already? what remains?
- contributed to development of open-source packages: mbuild, foyer, signac, fresnel
 this has helped me learn best software development practices like writing documentation, using version control, writing unit tests, employing CI, fork/pull model, etc. using these tools will help me to me a more efficient developer. It's also helped me to learn how to work as part of a team.
 - created MWE of coarse-graining and backmapping with smiles-- these will need furthertesting as we try them on different compounds but the proof of concept is there.
 - created tutorial examples to help current and future students understand scientific concepts and how to use computational tools
 - created GIXStapose (presented at SciPy2020) an interactive diffraction/structure viewer. This may seem unrelated but we can use diffraction to verify our opv morphologies and compare them to experiment. GIXStapose helps to beeter connect the physical structure with the diffraction pattern.
- started development on UFF repo for foyer. This is an example of how to create a version controlled forcefield which can be automatically applied to a compound. (atom typing is a pain)

#what is the timeline?
#what answers will be immediately forthcoming?
#what additional major research will result?

#will the work involve an outreach component?

#Intellectual merit and broader impacts?







Garbage first pass at abstract--probably just delete.

In order to make the most efficient opvs we need to find the best blend of compounds and the processing conditions that result in the best structure for those compounds. With minor modifcations the number of compounds and the processing conditions can become infinite which makes this an intractable problem for experiment.
by using a simulation pipeline, we can help to streamline the process of determining which opv materials will help to solve the energy crisis
simulation also helps to give us insight into the atomic interaction which drive self assembly.
a complication of this simulation is that the features which are important to the performance of an opv span multiple length scales. The electronic properties are important for light absorption, charge transfer <morehere>
while the bulk morphological properties are important: an exciton needs to be able to find an interface at which to dissociate before it decays through one of its non-radiative processes and one the charges are separated they need to reach an electrode in order to generate current and produce electricity. <interfacial area and connectivity>
"all models are wrong but some are useful" - George Box 1976 
it is not only computationally intractable to try and simulate the electron density of an opv polymer melt on length scales proportional to the exciton dissociation length (~5-10 nm) -- it is the wrong tool for the job. if what we are interested in is the properties of the polymer in the bulk heterojunction then it is wise to abstract away any degrees of freedom which do not directly contribute to the self-assembly of the structure. once a good bulk structure has been achieved these details can be reintegrated much more easily. This is the idea behind a coarse grain model.
my proposal is to develop a coarse-graining pipeline which will simplify the process mapping the coarse grain model onto the structure, parameterizing the forces and backmapping to retrieve atomistic details. 
<electronic structure, quantum > MD atomistic, classical forces> but each atom is represented > CG multiple atoms can be grouped together to form a super atom and then the effective force can be iteratively approximated using Boltzmann inversion (IBI). 
this has already been done-- lots of CG force fields already exist. The martini method <more> 
my idea is to use a systematic language for specifying chemical structure (SMARTS) to automate the bead mapping and backmapping. 
By creating an automation scheme which is understandable and makes chemical sense, we hope to simplify the process of creating and using a coarse-grain model.
we can use this do develop new coarse-grain models and test their efficacy in predicting charge transport.
