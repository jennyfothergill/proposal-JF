\section*{Motivation}

The global climate crisis is one of the most pressing issues humanity faces today.
Consumption of fossil fuels for energy and transportation is the primary contributor to rising atmospheric $CO_{2}$ levels\cite{Solomon2009a}.
Changes in the climate influenced by atmospheric $CO_{2}$ are long-lasting, devasting, and inequitable, often impacting the poorest nations the hardest.
Global energy consumption is predicted to increase from 19 TW in 2020 to 27 TW in 2040\cite{Mazzio2015, ieo2020}.
Solar power represents one way to sustainably meet our energy demands and there is opportunity to increase the contribution of solar energy generation to green energy.
Despite improvements in solar power generation over the last 40 years, the cost of photovoltaics (PVs) has prevented solar power from being a large part of the energy generation portfolio.
In order for solar power to be a viable option, large scale PV technology needs to be more economical and efficient\cite{Mazzio2015,Espinosa2012}.

Organic photovoltaics (OPVs, see~\autoref{opv}) are a focus of this research because they represent the best opportunity for cost effective solar power.
The theoretical efficiency limit (Shockley-Queisser limit) for a p-n single junction solar cell is about 30\%\cite{Shockley1961}.
Multijuction cells may achieve efficiencies that surpass this limit, but they often do not have lower energy payback times as their production is more costly.
\autoref{nrel} shows the efficiency gains made by single junction silicon and organic photovoltaic devices over the last 30 years.
These are merely a selection among the many categories of PV devices.
The trend of the silicon cells shows that the efficiency gain is levelling off as the devices approach the Shockley-Queisser limit.
OPV devices, however, still have a lot of room for improvement, and recent increases in efficiency reflect this.
\begin{wrapfigure}{l}{0.5\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/dou-miller2018c-fig.pdf}
    \caption{(a) roll to roll printing process for OPVs, (b) example OPV device, (c) bulk heterojunction structure, and (d) OPV energy generation process. Part (a) adapted from ref~\cite{Dou2013}. Parts (b,c,d) adapted from ref~\cite{Miller2018c}.}\label{opv}
\end{wrapfigure}
Many of the latest advancements in OPV technology have been through specialized processing or combinations of new chemistries.
One new chemical moiety which has recieved attention is the ladder backbone structure seen in many non-fullerene acceptors (NFAs), see \autoref{chemistries}.
In 2018, a single junction cell using an NFA achieved a record-breaking 13.25\% efficiency\cite{raynergy}.
And in 2019, a cell using an NFA functionalized with chlorine groups was found to achieve 16.5\% efficiency\cite{Cui2019}. 
Ultimately, the efficiency of a solar cell depends on the self-assembly of its active layer.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{images/NREL2020.pdf}
    \caption{Comparision of efficiencies organic and silicon photovoltaic technologies from 1990 to present. The current state-of-the-art OPV, polymer-fullerene device coupled with a transition metal disulfide, achieves 17.4\% efficiency\cite{Lin2019}. Data taken from~\cite{NREL2020}.}\label{nrel}
\end{figure}

In order to make the most efficient OPVs we need to find the blend of compounds and processing conditions that result in the best structure for those compounds.
The active layer of an OPV is mixture of electron-donor and acceptor compounds: 
With minor modifications, the number of compounds and the processing conditions can become infinite which makes this an intractable problem for experiment (see~\autoref{chemistries}).
This wide range of compounds provides the freedom to tune our OPVs, but it also increases the scope of the problem.
Imagine, you are a chemist preparing and testing new OPV morphologies: you are specifically looking at a mixture of a non-fullerene acceptor, ITIC, and a polymer donor, PTB7. 

\begin{wrapfigure}{l}{0.5\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/chem_structures.pdf}
    \caption{Chemical structures of polymer donors (P3HT and PTB7) and acceptors --- fullerene (PC$_{61}$BM) and non-fullerene (ITIC).}\label{chemistries}
\end{wrapfigure}
\noindent Each compound costs \$500 for 100 mg\cite{sigmaaldrich}.
The solvent you use and the concentrations of your active compounds changes the device performance\cite{Hoppe2004a}.
The amount of time the solvent is allowed to evaporate changes the device performance\cite{Li2007}.
The time and temperature of the thermal annealing changes the device performance\cite{Ma2005}.
The regioregularity of your polymer affects the device performance\cite{Kim2006}.
The distribution of polymer lengths affects the device performance\cite{Zhao2013b}.
Changing the functional groups on ITIC changes how it packs in a crystal, its electron affinity, and thus its performance in a device\cite{Swick2019a}.
All this would be to determine the performance of just one donor/acceptor combination in one category of potential compounds\cite{Dou2013}.
This is where molecular simulation can help.
By using a simulation pipeline, we can help to streamline the process of determining which OPV materials will form the morphology with the best charge transport, and in turn, help to solve the energy crisis.

Simulating an OPV morphology requires careful consideration. %% reword
A complication of the simulation of OPV polymers is that the properties which predict a device's efficiency, for example charge transport, span multiple length scales.
So, in order to model this system, a multiscale approach is necessary.
By breaking our simulation apart into separate steps and equilibrating different lengths scales individually, we can get equilibrated morphologies on multiple length scales more efficiently.
Another complication of this research is its computational scope.
If this project is going to have the desired impact (i.e., using molecular simulation to identify novel OPVs), every step of the process and the resulting data must be reproducible and validated.
The nature of a multiscale simulation requires translation between formats and units and accurate handling of large data, and thus requires infrastructure to reduce error.
By adhering to recent guidelines in the computational sciences community, we can strive to make tools which make science more transferrable, reproducibile, usable, and extensible (TRUE)\cite{Thompson2020}.
Although the molecular and computational scope of this project is broad, by using and building upon existing architectures we can manage the multiscale nature of this project and contribute reproducible science. %% omg help words are hard.

For this research we propose to develop a flexible method for specifying coarse-grained models to obtain OPV polymer morphologies equilibrated on length scales relevant to charge transport.
We also propose to develop a backmapping method, which works on the same simple mapping operator, to restore the atomic positions in preparation for techniques which require atomic level resolution, e.g., charge transport calculations.
This two step process is necessary because starting with the fully atomistic structure would not only be computationally inefficient but also the result may be less accurate due to the difficulties of equilibrating polymers\cite{Gartner2019a}.
This efficiency is important because the scope of potential OPV compounds is vast and the energy crisis necessitates expediency.
The number of OPV compounds to test quickly becomes intractable when we consider that the power conversion efficiency is strongly linked to minor chemical modifications or functionalization, device processing, and the interplay between donor and acceptor\cite{Mazzio2015,Swick2019a}.
There are countless variations of electron donor polymers, fullerene acceptors, and more recently small molecule, non-fullerene acceptors (NFAs) have been recieving attention for their potential to achieve higher efficiencies than their fullerene counterparts\cite{Dou2013}.
A P3HT:NFA blend was shown to have 11\% PCE, compared to the state-of-the-art 6.4\% in P3HT:PCBM\cite{Baran2017}.
Not only are NFAs found to be more efficient, but they also show to be more stabile in air than polymer:fullerene blends (retaining 70--80\% of the PCE after 1,200 h exposed to air while the fullerene device was no longer operational after 800 h)\cite{Baran2017}.
Coarse grain models do not yet exist for many of these NFAs, and with so many varieties an adaptable pipeline makes more sense than a single model.
It is necessary to develop a simple, useable, and flexible pipeline to adapt to the constantly changing chemistries of current OPV technologies.

\section*{Research Objectives}

Ultimately the goal this research is to help solve the global energy crisis. 
Solar energy is an important part of a green energy solution.
This research aims to gain insight about new OPV compound morphologies using molecular simulation.
In order to achieve this goal, we have defined the following objectives:
\begin{enumerate}
    \item {Develop a generalized toolset for coarse-graining and performing simulations of novel molecules for organic photovoltaics}
    \item {Develop a general tool to calculate atomistic positions from a coarse-grained morphology}
    \item {Predict nanostructures of novel OPV chemistries}
    \item {Identify chemical features correlated with robust self-assembly and good charge transport}
\end{enumerate}

In order to model these OPV polymer systems on relevant length scales, it is necessary to develop new coarse-grained models.
A flexible and efficient coarse-graining scheme will simplify the process of mapping and parameterizing these coarse-grained elements.

The flexibility of specifying a mapping will allow for the comparison of multiple mappings which may provide insight into the features of an OPV which govern its self-assembly and the limits of coarse-grained models.
Currently there is no agreed-upon ``best'' scheme for a coarse-grained mapping operator.
By making a simple and easy-to-use coarse-graining tool, many mapping operators can be tested and the limits of a minimal model can be probed.

Making this tool usable will also contribute to reproducibile science. 
Integrating with existing open source software packages will provide the most benefit and also increase transferrability and usability.
We will use packages like signac for managing dataspaces, foyer for version control of forcefields, mbuild for building chemical structures, hoomd for running molecular dynamics simulations, freud for simulation trajectory analysis, and Open Babel for recognizing chemical patterns\cite{signac, foyer, mbuild, hoomd, freud, openbabel}.
These are established codebases which are actively developed and engine agnostic (except hoomd which is in itself an engine).

Demonstrating a workflow from start to finish with explanations using easy-to-understand language, diagrams, and figures makes a codebase more usable and approachable but does not interfere with it being modular or efficient.
Ultimately a goal of this research is that it is used by others: as an example to build upon or as a template for setting up their own experiments.

\section*{Background}

\subsection*{Organic Photovoltaics}

%Renewable energy accounted for 11\% of the U.S. energy consumption in 2019 and of that 9\% was from solar (approximately 1\% of the total energy)\cite{USEIA2020}.
%However, our energy infrastructure has room for improvement: consider Germany which in 2019 got 43\% of its energy from renewables and 8.2\% of its total energy from solar\cite{Wirth2017}.

The performance of an OPV device can be quantified by many metrics.
The power conversion efficiency (PCE or sometimes $\eta_{e}$) is the ratio of electrical power produced by the device to the power of incedent photons.
Higher PCE means the device is more efficient.  
The material properties which determine the PCE of a device are those which affect the number of photons absorbed, excitons dissociated, and free charges that reach the electrode.
The absorption efficiency depends on the absorption spectrum, absorption coefficient, and layer thickness.
The fraction of excitons which dissociate depends on the exciton dissociation length and the charge separation probability at the interface.
Finally, the the number of charges which reach the electrode depends on the driving force or gradient resulting from the potentials of the electrons and holes\cite{Hoppe2004}.
%%<is there a citation for why charge transport is a good proxy for PCE?>

Traditionally, photovoltaic (PV) devices, which can convert incedent light into electric current, were made of inorganic materials like silicon.
But in the late 1970's organic photovaltaics (OPVs) were discovered as a potential alternative\cite{Tang1986b}.
The advantage of OPVs over inorganic PV devices is that OPVs are lightweight, low cost, easier to produce, and flexible. 
OPVs can be manufactured large scale in a roll to roll printing process, similar to newspaper, as shown in~\autoref{opv} a\cite{Dou2013}.
Inorganic PV devices came first and are still the most efficient, but they are more costly to produce, use rare elements, and their production causes other environmental issues, so they aren't the best solution for solar energy harvesting. 
The first OPV was created by Tang in 1986 and used a bilyaer structure containing copper phthalocyanine and a perylene derivitive\cite{Tang1986b}. 
This early device had a PCE of 0.95\%.
In 1992, Sariciftci and Heeger were the first to report using a fullerene as an electron acceptor in a fullerene:polymer mixture\cite{Sariciftci1992}.
And in 1995, Yu described the first bulk heterojunction (BHJ), as an interpenetrating network of donor and acceptor that maximizes the interfacial area, which is still the state of the art morphology to this day\cite{Yu1995}.
Most recently, non-fullerene acceptors (NFAs), like ITIC, are contributing to the PCE increase of modern OPVs\cite{S.Gurney2019b}.

\begin{wrapfigure}{l}{0.5\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/ITIC.pdf}
    \caption{ITIC chemical structure with \textcolor{red}{electron accepting regions in red} and \textcolor{blue}{electron donating regions in blue}}\label{itic}
\end{wrapfigure}

The planar acceptor-donor-acceptor moeity seen in many NFA backbones (see \autoref{itic}) may have more efficient exciton splitting, as compared to a fullerene acceptor, at the heterojunction due to strong electronic coupling between the conjugated backbones of the NFA and the polymer\cite{Yi2018a}.

The compounds which compose an OPV are synthesizable molecules (often polymers) composed of abundant elements (carbon, hydrogen, nitrogen, sulfur, oxygen).
Due to the conjugated pi-orbitals in these molecules the absorption of sunlight can excite an electron into a frontier orbital and generate an exciton, a couloubicly bound electron-hole pair.
OPVs are made as a mixture of electron-donor and electron-acceptor compounds in a structure called a bulk-heterojunction.
Depending on the bulk morphology of these compounds, the exciton can travel to an acceptor-donor interface and dissociate into free electron and hole then these free charges generate current if they can subsequently make their way to an electrode.

The morphology of the device can be affected by the processing conditions: temperature, solvents, and concentrations/ratios of the active compounds\cite{Ma2005,Hoppe2004a,Li2007}.
The interfacial area of the acceptor:donor regions\cite{Mazzio2015}, the regioregularity of the polymer\cite{Kim2006}, and electronic properties of the compounds\cite{Scharber2006a} all play an important role in the power conversion efficiency (PCE) of the device. 
These changes in structure can strongly affect the device performance.
Molecular simulation allows us to ``see'' these atomic interactions and gain a deeper view into the driving forces behind the self assembly of these OPV morphologies and to understand what conditions create the best devices.

%The atomic and electronic properties are important for light absorption, in which an exciton is created, and charge transfer, where the exciton is dissociated into a free electron and hole\cite{Scharber2006a,Hoppe2004,Mazzio2015}.
%At the same time, the exciton finding an interface at which to dissociate and the separated charges finding a path to an electrode both depend on the morphology of the active layer.
\subsection*{Molecular Dynamics}

\begin{wrapfigure}{l}{0.5\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/bondangledihedral.pdf}
    \caption{Bonded interactions: bond (top left), angle (top right), and dihedral (bottom). Image adapted from~\cite{punma}.}\label{bad}
\end{wrapfigure}
Molecular dynamics (MD) is a simulation tool which uses classical physics and statistical thermodynamics to sample the equilibrium states of a thermodynamic ensemble.
The MD algorithm integrates Newton's equations of motion to update the particle positions.
This process can be iterated until the system reaches equilibrium.
MD is the right tool for looking at the bulk structure of an OPV because we can simultaneously probe the thermodynamics which govern OPV self assembly and the kinetics that follow the device processing.
Other tools, like Monte Carlo (MC), may allow us to sample equilibrium states of an ensemble, but we would lose information about the dynamics.
MC is also inefficient for polymers because perturbing a long chain of particles requires a ``cluster move'', which is not parallelizable.

\begin{wrapfigure}{l}{0.5\linewidth}
    \begin{center}
        \includegraphics[width=\linewidth]{images/lj.pdf}
        \end{center}
    \caption{The Lennard-Jones potential with relevant distances labelled}\label{lj}
\end{wrapfigure}
MD separates the interactions between particles into non-bonded interactions and bond, angle, and dihedral interactions (see \autoref{bad}).
Non-bonded interactions are commonly modelled with a Lennard-Jones potential:
\[
    U_{LJ}(r_{i,j}) = 4\epsilon\big[
        {\big(\frac{\sigma}{r_{i,j}}\big)}^{12}-
        {\big(\frac{\sigma}{r_{i,j}}\big)}^{6}
        \big]
\]
Where $i$ and $j$ are the particles separated by distance $r_{i,j}$.
The equilibrium distance between particles is controlled by $\sigma$ and the depth of the potential well is controlled by $\epsilon$ (see \autoref{lj}).
A distance cutoff, $r_{cut}$, is often used to reduce the number of pairwise interactions and improve performance.
Particles connected by bonds are also modelled by classical forces, for example the bond potential may be treated as a harmonic oscillator:
\[
    V_{bond}{(r)} = \frac{1}{2}k{(r-r_{0})}^{2}
\]
Where $r$ is the bond length, $r_{0}$ is the equilibrium bond length, and $k$ is the spring constant for the bond.
The angle potential is also treated as a harmonic oscillator:
\[
    V_{angle}{(\theta)}=\frac{1}{2}k{(\theta-\theta_{0})}^{2}
\]
Where $\theta$ is the angle formed between three bonded particles, $\theta_{0}$ is the equilibrium angle, and $k$ is the spring contant for the angle.
The dihedral potential can be defined by the follow Fourier series:
\[
    V_{dihedral}(\phi)=\frac{1}{2}k_{1}(1-\cos(\phi))+\frac{1}{2}k_{2}(1-\cos(2\phi))+\frac{1}{2}k_{3}(1-\cos(3\phi))\frac{1}{2}k_{4}(1-\cos(4\phi))
\]
Where $\phi$ is the angle between planes formed by particles in the dihedral (see \autoref{bad}) and $k_{n}$ are the force coeffients.

%% transition???
The first MD simulation modelled a system of 108 particles and completed 200 collisions in one hour on an IBM-704\cite{Alder1957}.
Now GPUs are a 100 million times faster.
Due to its the simplicity and efficient scaling, MD is now commonly used for the modelling of protein folding\cite{levitt75} and other biological processes, and investigating the bulk properties of polymers\cite{Gartner2019a}.

%% remove?
%Even all-atom MD is not without assumptions:
%In general, during an MD simulation bonds aren't formed or broken, so without careful consideration this prevents the study of chemical reactions.
%MD does not consider electrons, instead atoms are treated as point particles. 
%This makes modelling systems which depend on hydrogen bonding or dispersion more difficult.

Even with the simplifications of MD, we are still not able to simulate many systems efficiently on relevant length scales.
By abstracting away some of the atomic degrees of freedom which do not contribute as much to the bulk structure, MD can be used to look at even larger systems.
Coarse grain models are one such technique to increase the length and time scales examined by a simulation.

\subsection*{Coarse Grain Models}

Coarse graining refers to grouping atoms in a structure into a ``super atom'' and using an effective potential to represent the resulting coarse-grained site.
This effective potential used to represent the reduced system results in a smoothed free energy landscape. 
The heart of coarse-graining is the removal of degrees of freedom. 
Coarse grain models allow for simulators to access length and time scales that would be otherwise impossible using atomistic models by abstracting away irrelevant degrees of freedom.
Processes which may have taken many time steps in an all atom simulation can take fewer time steps in a coarse simulation\cite{Berendsen2010}.
Due to their long length and time scales, coarse-grained models are ideal for examining polymer properties\cite{Gartner2019a}.
Similarly to how monitoring the working of a plant cell is not necessary to understanding the growth of a forest, some atomic level properties do not need consideration when simulating the bulk morphology\cite{Muller-Plathe2002}.
It is too big, too slow, and unwise to simulate huge boxes of atomistic polymers.
Even if the simulation was to complete, there would be too much information to process accurately. 
Coarse graining allows scientists to \textit{focus} their experiments\cite{Baschnagel2000}.

The resolution of coarse-grained systems is broad:
Simply grouping hydrogens with the heavy atom they are bonded to, called the united-atom model, has been shown to speed up dynamics and make polymer length scales more easily accesible\cite{Paul1995a, Yang2006a}.
Other coarse-graining schemes may group functional groups together\cite{Berendsen2010, Jankowski2013, Marsh2014}, one site per repeat unit in a polymer\cite{Lee2011}, or even represent an entire amino acid with a single site\cite{Peng2019}.
General coarse-grained models of OPV thiophene polymers where only the spacing and regioregularity of the side chains were varied were able to predict order disorder transitions and scattering patterns comparable to those obtained from experiment\cite{Jankowski2013, Marsh2014}.
A coarse-grained model for phospholipids has allowed for bilayer formation from an initial random configuration to be simulated even though the model was parameterized to the vapor-liquid phase transition\cite{Shelley2001}.
Which model is right depends on the length and time scale on which the property of interest can be observed.

For many systems, however, we are interested in properties which span length scales.
For instance, in a system like a OPV polymer melt, it is not only computationally intractable to try and simulate the electron density on length scales proportional to the exciton dissociation length (~5--10 nm)\cite{Huang2010}; it is the wrong tool for the job.
If what we are interested in is the properties of the polymer in the bulk heterojunction, then it is wise to abstract away any degrees of freedom which do not directly contribute to the self-assembly of the structure.
Once a good bulk structure has been achieved, the atomistic details can be reintegrated much more easily: a process called backmapping.
In the same way that a coarse-grained model can be mapped onto an atomistic one, we can get a reasonable starting structure for an atomistic simulation from a coarse-grained structure.
The large length scale, polymer level properties can be equilibrated during the coarse-grained simulation, and then the atomic interactions can be equilibrated during the backmapped atomistic simulation.
This can allow us the calculate properties such as charge transport, which depends upon the electronic structure of individual chromophores \textit{and} the connectivity of these chromophores over distances proportional to the exciton dissociation length.

%% HELP transition?
%%<what stands in our way?>
%%<coarse-grain models are specific>
%% EJ: Discuss in-person?

%% HELP is the following paragraph/section too big? 
%% EJ: It's a little rambly, but definitely not bad. One check we can do in the background is check for each paragraph or subsection, have we clearly identified outstanding problems or gaps in knowledge, and check whether mention them in the motivation? I expect this kind of check will help "tidy up" this paragraph.
Part of coarse-graining process that is not yet automated is choosing a mapping scheme or a mapping operator.
A mapping operator defines which atoms are grouped into a ``super atom'' represented by one coarse-grained site and where the site is placed relative to the atom group.
Mapping operators are chosen based on the desired resolution of the coarse-grained system and the information to be extracted.
A straightforward way to define a mapping operator is to group a set number of heavy atoms (non hydrogen) together; this is the method used in the notable MARTINI force field\cite{Marrink2007}.
In this scheme, four atoms (except rings, which are treated differently) are grouped and the site is classified as polar, non-polar, apolar, or charged depending on the atoms it is composed of.
When parameterizing a new molecule for the MARTINI method, a user must pick a mapping and then compare the chemical structure of the resulting sites to those which have already been parameterized; a process which is time consuming and error prone\cite{martini-tutorial}.
The published tutorial recommends searching through existing MARTINI topologies to find similar structures and then manually editing them to fit the new molecule.
Whether the structure is similar then is based on the user's chemical knowledge, judgement, and intuition.
Many other mapping schemes also rely on the user's chemical intuition (e.g., what parts of the molecule shouldn't be allowed to bend? What groups have the most dominant interactions in this structure)\cite{Huang2010, Knotts2007}.
As the number of atoms in the fine grain structure increases, the number of possible mappings increase drastically.
There have been efforts to create algorithms for automating the process of deciding which atoms are grouped in a ``super atom''.
One study reduced the number of allowed mappings by only allowing those which do not change the symmetry group, then iterated over a graph of all possible mappings to find the ``best'' mapping by comparing the difference between the mapped RDF and velocity autocorrelation function\cite{Chakraborty2018b}.
Another uses principle component analysis to choose a mapping scheme for biomolecules that best represents th essential dynamics\cite{Zhang2008}.
Mapping operators can be automated using machine learning: clustering methods combined with graph analysis were shown to predict the ``expert'' mapping chosen using chemical intuition reliably\cite{Li2020}. 
A mapping operator based on the centers of charge was shown to accurately model electrostatic properties\cite{Cao2015a}.
Deciding on a mapping operator is one part of creating a coarse-grained model, the second step is to create an effective potential for the site.

\subsection*{Multi-State Iterative Boltzmann Inversion}

There are numerous methods for deriving coarse-grained potentials from atomistic ones (e.g., force-matching, reverse Monte Carlo), but in this proposal we will focus on Iterative Boltzmann Inversion (IBI).
IBI is where a coarse-grained potential is iteratively tuned to fit a target distribution usually from an atomistic simulation\cite{Reith2003}.
The radial distribution function (RDF) describes the probability of finding a particle at a given distance from another particle.
The RDF can be used to investigate properties such as the density or the phase of a system and the RDF is used in IBI as the target distribution for the non-bonded potentials. %%reword?
The process for determining the non-bonded potentials using IBI is as follows:
\begin{enumerate}
    \item 
        The coarse-grained system is mapped onto an equilibrated atomistic one.

    \item 
        The average RDF of the mapped system is calculated over the equilibrated frames of the trajectory --- this is the target distribution.

    \item 
        Taking the Boltzmann Inverse of the RDF results in the potential of mean force (PMF):
        
        \[
            F(r) = -k_{B}T \ln g(r)
        \]
        
        Where $F(r)$ is the PMF, $k_{B}T$ is the thermal energy, and $g(r)$ is the target distribution.
        Although $F(r)$ is a free-energy and not a potential energy, it is sufficient to be used as the initial potential ($V_{0}$) in the iterative scheme\cite{Reith2003}.

    \item
        A simulation can be run using the PMF as the non-bonded potential to achieve a new distribution.

    \item
        The difference between the new and target distribution can be accounted for in the next iteration accoring to the following equation:
        
        \[
            V_{i+1}(r) = V_{i}(r) - k_{B}T \ln\bigg(\frac{g_{i}(r)}{g(r)}\bigg)
        \]

        Where $g_{i}(r)$ is the distribution obtained using the potential $V_{i}(r)$.

\end{enumerate}
This process is repeated until the difference between the result and the target is sufficiently small. 
The bonded distributions can be similarly iterated to obtain the bonded potentials; however, in some cases the Boltzmann inverse of the bonded distribution may be used without iteration\cite{Reith2003}.

The coarse-grained potential derived from IBI is not transferrable to different thermodynamic statepoints.
This is because the RDF is a property of the ensemble average at a given statepoint, so the potential derived from this property is also limited.
For example, separate potentials are required to capture solid and fluid structures of a pure simple lipid~\cite{Hadley2010a}.
There are many attempts to create transferrable CG potentials, for example:
The TraPPE force-field fits CG potentials using vapor-liquid equilibria to improve transferrability across thermodynamic states\cite{Maerzke2011}.
But optimization to the liquid-vapor equilibrium, although useful for prediction of thermodynamic properties, may not be ideal for prediction of structure which will strongly influence charge transport.
%%<so we probably want to create our own potentials>
%%<IBI potentials are sometimes transferrable and it is not clear why sometimes they are and sometimes they aren't.>~\cite{Moore2014}

\begin{wrapfigure}{l}{0.5\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/moorefig.pdf}
    \caption{Visualization of the state space coverage of different potentials: if the thermodynamic states are too similar (b), then the overlap region is large enough that there are many potentials which will fit the target. Choosing states which are different (a) will better define the potential. Image adapted from ref~\cite{Moore2014}.}\label{moore}
\end{wrapfigure}

Multistate iterative Boltzmann inversion (MS IBI) includes data from multiple targets to yield a less state dependent potential\cite{Moore2014}.
The MS IBI potential is an average of the single state potentials with a weighting function to prioritize a state of interest.
This method has been shown to accurately reproduce the true potential in monoatomic LJ fluid.
When using the MS IBI method, it is important to choose dissimilar states to minimize the potential overlap region.
If this overlap region is large, there are many potentials which will provide matching RDFs (see \autoref{moore}).
For some systems there may not be a potential that represents all states; this is not unique to coarse potentials, atomistic potentials also have this limitation. \ej{the second half of this sentence is a big idea that we might consider unpacking more, or maybe omitting?}

%% HELP transition
%%<need some tie in back to why we would want to go from CG--->atomistic>
%% EJ: Chat in-person

\subsection*{Mesoscale Device Simulation}

In order to use coarse grain models to predict charge transport, we need a way to translate from the coarse to the atomistic morphology.
%% HELP transition
MorphCT, a software previously developed by our lab, can simulate charge transport through an OPV morphology using kinetic Monte Carlo\cite{Miller2018a,MorphCT,morphct2.2}.
The kinetic Monte Carlo algorithm used by MorphCT uses the semi-empirical Zerner's Intermediate Neglect of Differential Overlap (ZINDO/S) quantum chemical calculation to obtain the molecular energy levels of chromophores in the morphology.
The HOMO levels of each chromophore site and the energy splitting induced in the chromophore pairs is used in the Marcus equation to calculate the charge hopping rate between pairs.
A Monte Carlo simulation can then be run using these hopping rates to calculate the movement of charges through the system.
Because this is a quantum chemical calculation, the position of each atom is needed; therefore, a backmapping process is required to calculate the charge transport in a coarse-grained morphology.

\subsection*{Molecular Simulation Infrastructure}

Already good, open-source packages exist to address the problem of coarse-graining and/or backmapping\cite{Marrink2007,Ruhle2009,Maerzke2011,MorphCT,Wassenaar2014b}. %% these citations are martini, votca, trappe, morphct, backwards.py
By making code open source and freely availiable, developers contribute to the knowledge of a global community. 
But just because something is availiable doesn't mean it is accessible: often just figuring out how to use an existing package can be very difficult\cite{Cummings2019}.
These existing codebases can appear to a new user as monolithic and indecipherable because their design has been to solve a problem, which they do, instead of design with a focus on how people learn.
These codebases also rely on users piecing together multiple, often incompatible, bits of software, using manually created xml files, or deciding how to classify an atom grouping based on the user's chemical intuition.
All of these factors contribute to a reproducibility crisis in the computational sciences\cite{Baker2016}.
By keeping best practices for software development and teaching in mind, we can strive to make tools which make science more transferrable, reproducibile, usable, and extensible (TRUE)\cite{Thompson2020}.
Best software development practices include using version control software, such as git, to facilitate the process of tracking and merging changes to a code repository, especially important when working collaboratively.
Also among these best practices are using unit tests and continuous integration to ensure that errors are quickly and automatically caught\cite{Wilson2014}.
Instead of writing dense, inseparable scripts which rely on the user manually following a command prompt or editing multiple text files, we aim to keep code small and modular to make it easier to use and understand\cite{Adorf2018a}.
Following these guidelines not only makes our code easier to develop and debug but also reduces the cognitive load for a new user\cite{Jankowski2019}.
Providing good documentation and tutorials is also imperative for onboarding new users.
Jupyter Notebooks, which are a combination of interactive code and formatted text and images, can be used like a lab notebook for computational scientists in order to demonstrate the process, rationale, and the story of each experiment and the exact steps to get the results shown\cite{jupyter, Rule2019a}.
When writing these tutorials, it is wise to remember that the data never speaks for itself: although including input and output files of a calculation is a good first step, they must be accompanied by the story of what the data means and how a user can know that meaning for themselves\cite{SWC, Wilson2016}.
\section*{Preliminary Work}

%% HELP this section is rough... not sure what to do.
My prior work has involved probing the intermolecular interactions which govern dimer and crystal formation.
An investigation of the excitonic splitting observed in cyanine dye dimers was done using density functional theory (DFT)\cite{Fothergill2018}.
By comparing calculated with experimental absorption spectra it was found that the solvent may play a large role in the dimer formation and peak shifting.
An investigation of the supramolecular interactions which guide crystal self-assembly in diphenylurea transition metal complexes was done using density functional theory\cite{Millard2019a}. 
My contributions to our perspective paper were mostly about my experience joining the lab and trying to reproduce an existing model; a task which should be very straightforward in a computational field but which any computational scientist can attest is far from simple\cite{Jankowski2019}. 
I also presented a tool I've developed, called GIXStapose, at the Scientific Python conference (SciPy2020)\cite{gixstapose, scipy2020}
GIXStapose is an interactive structure viewer alongside its simulated diffraction pattern.
This work had two goals: helping users to see the connections between a structure and it's diffraction pattern and making reproducible figure generation easier.
The first goal is achieved through a graphical user interface (GUI) which allows users to interact with the structure using the mouse and the diffraction pattern is updated automatically.
The second goal is accomplished by allowing all steps of the figure generation process (e.g., positioning the camera, setting the colors and lighting, etc) to be scripted and never \textit{requiring} use of the GUI\@.
These prior works, although not directly related to OPVS or coarse-grained models, have helped me think about how atomic interactions can shape a structure, the struggles that face a new computational scientist, and how I can help.

I have contributed to development of open-source packages including mbuild, foyer, signac, and fresnel\cite{mbuild, foyer, signac, fresnel}.
These contributions have given me ample opportunity to excercise best software development practices like writing good documentation, using version control, writing unit tests, employing CI, using a fork \& pull workflow, etc.
This experience will help me to be more efficient in my future work.
I've also gained valuable experience as working as part of a team.
As I plan to integrate my future work with existing projects, good collaborative skills will be necessary.

I have completed Software Carpentry training which has taught me how to break down complex ideas and give learners a chance to use their knowledge.
With these principles in mind, I have created tutorial examples to help current and future students understand scientific concepts and how to use computational tools\cite{notebooktutorials}

As for work towards my proposed plan, I have created a minimum working example of a coarse-graining and backmapping package which uses SMARTS strings to specify the site chemistries\cite{grits}.
This package will need further testing as it is tested on different compounds, but the proof of concept exists.

Packages which do coarse-graining and backmapping already exist, so why is another one necessary?
One such package, Versatile Object-oriented Toolkit for Coarse-graining Applications (VOTCA)\cite{Ruhle2011b}, includes a coarse-graining, forcefield creation with reverse MC or IBI, and back-mapping modules.
It also allows for charge transport calculations using KMC similar to MorphCT\cite{Lukyanov2010}.
VOTCA makes some progress towards a TRUE simulation pipeline: they include a docker container with their pre-built software stack and example input files.
However, some of these input files don't work and the unit test coverage on their examples repo at the of time of this writing is 0\%.
While including example inputs and a prebuilt software stack via docker is a great first step, these tutorials give very little walkthrough aside from code comments buried in the xml\cite{votca-github}.
\begin{wrapfigure}{l}{0.5\linewidth}
    \centering
    \includegraphics[width=\linewidth]{images/hexane-compare.pdf}
    \caption{Hexane chemical structure (top) overlaid with coarse-grained mapping \textcolor{blue}{A}-\textcolor{orange}{B}-\textcolor{blue}{A} (bottom)}\label{hexane}
\end{wrapfigure}
The code is a mix of C++, shell commands, and python, and the user is required to interact with compiled programs through the command-line which makes adding this code into an existing workflow a little more difficult.
Overall though this project has many features, interfaces with many popular MD engines (LAMMPS, GROMACS, HOOMD), and is under active, collaborative development, it is near-overwhelming in its scope and is not designed for the new user.
By choosing a pure python API I will be able to make use of Jupyter Notebooks which can be run on cloud servers using tools like MyBinder which can combine executable code with markdown text and images\cite{mybinder, jupyter, notebooktutorials}.
In this way a tutorial can provide exact commands needed to reproduce the example intimately connected with the rationale and justification of that example.

For an example of what I mean by cognitive load, let's compare an example of my proposed coarse-graining scheme to VOTCAs.
In the following example we will take a hexane molecule and map it to three coarse-grained sites (two carbon atoms per site, see~\autoref{hexane}).

VOTCA uses an xml file to do this:

\lstinputlisting[breaklines, basicstyle=\scriptsize\ttfamily]{hexane.xml}

%%\begin{wrapfigure}{L}{0.5\linewidth}
%%    \centering
%%    \includegraphics[width=\linewidth]{images/hexanexml.pdf}
%%    \caption{XML file used by VOTCA to specify a three site coarse-grained mapping of n-hexane}
%%    \label{hexanexml}
%%\end{wrapfigure}

It may be easy to think that because the goal is simple, mapping two carbons and their attached hydrogens to a single site so that six alkyl carbons becomes three coarse-grained sites (A-B-A), that the process will also be simple.
In order to specify a site-mapping using VOTCA, we need to know the residue number, the residue name, and the atom name.
For a six atom system this is not too bad, but it could get tedious and error-prone for larger systems.
And keep in mind that these xml files need to be created manually for each compound which is coarse grained or  backmapped.
VOTCA's scheme also requires that the bonding and the angles resulting from those bonds are specified, another process which is tedious, error-prone, and probably unecessary. 
To explain, let's discuss my proposed alternative:
\begin{lstlisting}
hexane_sites = [("_A", "C[CH3]"), ("_B", "CC")]
\end{lstlisting}
The result of using this code in the \lstinline{coarse} function is a three-site hexane model A-B-A, same as VOTCA\cite{grits}.
The mapping here is specified as a list of site name SMARTS string pairs.
Although they do add some element of cognitive load, SMARTS strings are designed to be human and machine readable and can match atoms based on their chemical environment.
With this scheme, there is no need to look up the name or number of each residue, I simply specify that want two alkyl carbons (in SMARTS notation a capital \lstinline{"C"} denotes an alkyl carbon) and requiring that one be a terminal carbon by including that it has three attached hydrogens (\lstinline{"[CH3]"}).
The order of the sites here matters because technically all the carbon atoms in hexane could be mapped with the more general SMARTS string (\lstinline{"CC"}), so it is important to list the most specific strings first.
The bonding and angles of the resulting coarse-grained sites can then inferred based on the bonding of the mapped atoms.
Basically what VOTCA's xml file does in 51 lines, I can do in 1 which is easier to read and makes chemical sense. 
There are even benefits to the mapping being inline with the code:
It allows the user to see the mapping as they progress through the workflow without having to search for multiple files.
Not using an external file may prevent common errors caused by manual file IO such as operating system specific line endings or whitespace characters like tab or space being read differently by a program.
Having the mapping in-line with the workflow also allows for the user to check that the mapping is correct with built in interactive visualizations, which can display the mapping as an overlay. 
(\autoref{hexane} is the output of one such visualization using py3Dmol\cite{py3dmol}.)

We propose a way to make the mapping and backmapping process easier for the user.
Simplified Molecular Input Line Entry System or SMILES was designed to represent organic molecules in an unambiguous way (similar to IUPAC) but in a line-entry system which is also readable by a computer\cite{Weininger1988}.
This makes it a good candidate for specifying a coarse-grain mapping scheme.
The open-source package, Open Babel, allows for a SMILES string to be converted to a chemical structure and vice versa\cite{openbabel, OBoyle2011}.
SMARTS is similar to SMILES but instead of representing a single molecule unambiguously, it has multiple wildcards which can be used for pattern matching\cite{daylight}.
This pattern matching is also implemented in the Open Babel package.
If we know the SMARTS string for any given CG mapping, we can map the CG site to its center of mass or geometric center.
I have developed a minimum working example of how this can be done and then how the atomistic structure can be recovered\cite{grits}.
This mapping scheme could even be used to make the mapping process easier for established coarse-grained models.
It could be fairly straightforward to implement a lookup to check if site parameters already exist (e.g., for the MARTINI model) by going through and writing out the SMARTS pattern for each existing site type.
This could make parameterizing new compounds for an existing method more foolproof.

\section*{Research Plan}

My plan is to create a workflow which builds on existing tools: signac, freud, mbuild, Open Babel, and a previously developed msibi package.
This workflow could start with equilibrated atomistic trajectories from multiple statepoints, then use SMARTS strings to map the CG sites to each trajectory and calculate the effective potentials using MSIBI\@.
Once we have a tabulated coarse-grained force field, we can create a larger simulation using our coarse-grained model.
Finally, once we have an equilibrated coarse-grained trajectory, we can using backmapping to regain the atomic positions and do analyses, e.g., radial distribution function (RDF), charge transport, and diffraction.
If this workflow is streamlined, it can be applied to many different compounds allowing for a high-throughput analysis of many potential OPV compounds.

\subsection*{Objective 1: Develop a generalized toolset for coarse-graining and performing simulations of novel molecules for organic photovoltaics}
In order to model the morphologies of new OPV chemistries, we need a simple way to generate novel coarse-grained models.
This objective consists of three steps:
\begin{enumerate}
    \item {Create a tool that uses a mapping operator to go from atomistic to coarse-grained structure}
    \item {Use the mapped coarse-grained structure to parameterize a force field using MSIBI}
    \item {Develop the infrastructure to port this force field to a simulation engine}
\end{enumerate}
A minimum working example of this coarse-grained mapping tool has been completed\cite{grits}.
However, it will still need to be tested with many more compounds and mapping operators.
This package uses the chemical file format parsing and scriptable structure building capabilities of mbuild coupled with the SMARTS/SMILES string matching of the Open Babel package to generate coarse-grained structures mapped onto their atomistic counterparts with only a SMARTS string from the user.
These coarse-grained structures mapped to an atomistic target can then be used in an MSIBI workflow to obtain an effective potential.
A minimum working example of an MSIBI tool has also been started; however, although the hands-on experience with MSIBI was useful to me in getting a better understanding for the process, I think for future, I will build off an existing MSIBI code\cite{msibi, Moore2014}.
The force field obtained using MSIBI will then be used to run a simulation of a novel coarse-grained model.
Therefore decisions about how to carry the forcefield information into a simulation engine will need to be made.
For this, we will make use of and build upon the simulation setup capabilities of mbuild.

\textbf{Completion Critera:} Force fields and initial configurations usable with HOOMD-Blue that enable the equilibration of: 5 polymers, 5 fullerene derivatives, and 5 ITIC derivatives. 

\subsection*{Objective 2: Develop a general tool to calculate atomistic positions from a coarse-grained morphology}

In order to calculate the charge transport of a coarse-grained representation of a morphology, we need to be able to estimate the atomic positions.
Given an equilibrated coarse-grained trajectory, we can reintroduce the atomistic degrees of freedom by using the same SMARTS mappings used for coarse-graining.
The chemistries specified by the SMARTS strings will be mapped onto the centers of the CG sites and then equilibrated in a short MD run using the atomistic force field with an additional position restraint to maintain the structure. 
This method is not fundamentally different from many existing backmapping routines in that the atomistic structure is naively positioned over the coarse site and then relaxed --- the main difference lies in the amount of additional work required from the user\cite{Wassenaar2014b, MorphCT, Ruhle2009}.
Since the user has already specified the mapping to go from atomistic to coarse, it can be reused for backmapping.
The bonding between the atomistic structures of the sites is lost, so this information will need to be provided: either specified by the user or recorded during the coarse graining step.
I have developed a minimum working example of this backmapping process\cite{grits},
however, the specification of how the backmapped atomistic structures are bonded is still not intuitive for the user to specify and I have yet to implement automated tracking of the conds during the coarse graining.

\textbf{Completion Critera:} The ability to perform charge-transport calculations of 5 polymer, 5 fullerene-derivative, and 5 ITIC-derived OPV morphologies that have been back-mapped from coarse-grained representations.
%%\ej{Here's candidate text with being able to USE the back-mapped morphologies, but maybe we want something easier here?} - i'm ok with this goal.

\subsection*{Objective 3: Predict nanostructures of novel OPV chemistries}

Once Objectives 1 and 2 are complete, the next step will be putting them to use to investigate new OPV compounds. 
%%\ej{In principle we could also start this without new models: That's what Gwen and Emily are doing!}
Currently, I have not found CG models for many NFA compounds (e.g, ITIC). %% I found this paper~\cite{Meng2019} that claims to do CGMD with PTB7 ITIC but the details are hidden in the SI and seem fishy. seems like they use IBI but they dont say how they got their target distributions.
A simple, useable coarse-graining tool will be helpful for determining the best mapping operator to use for these OPV compounds.
To help organize the dataspace of the large parameter sweep, I plan to use the signac package to manage an ever-changing workspace.
This will help easily and efficiently test out different mappings and ``processing'' conditions.

\textbf{Completion Critera:} 
Validation using diffraction or RDF of simulated morphologies composed of 5 polymers, 5 fullerene derivatives, and 5 ITIC derivatives. 
%%\ej{Some number of predicted morphologies and/or some number of morphologies validated against experiments. }

\subsection*{Objective 4: Identify chemical features correlated with robust self-assembly and good charge transport}

Our lab has shown that we have the capability to compare our simulation results to experiment using hole mobilities from charge transport calculations\cite{Jones2017,Miller2018a} and grazing incedent X-ray scattering (GIXS) patterns\cite{Miller2018}.
GIXS calculations on our backmapped trajectories can be used to validate that our simulations result in the same morphology as experiment.
While charge transport calculations can be used to rate the efficacy of the active layer morphology.
Using our lab's charge transport package (MorphCT) on new chemistries, however, will require some work.
Many of the parameters and the definition of the chromophore are hard-coded for poly-3-hexylthiophene (P3HT).
Moving this package away from a command line interface will also be a goal of this work.
%%Our morphct paper says the mobilities we predict are 2x higher than experiment? why?
%%<adding in calculation of reorganization energy??> 
%%<or just ripping out the KMC bit and making it modular>

\textbf{Completion Critera:} \ej{todo}

\section*{Predicted Outcomes}

\ej{One thing this section is missing right now are tangible things that we specified in our Research Objectives. These include: XX new models of OPV chemistries; XX new tutorial notebooks for doing YY\@; XX predictions of OPV morphologies; Implementations of best practices others can copy or extend; }
As a result of this work, we expect the following outcomes:

\begin{enumerate}
    \item {\textbf{Gain insight into the limits of coarse-graining}}
        This work will probe the limits of coarse-graining to understand the minimal model necessary to represent different OPV chemistries.
    \item {\textbf{Understand the interactions which guide BHJ self assembly}} 
        This work will test a variety of different OPV compounds. 
        Comparing the results may provide understanding into which moeities, intermolecular interactions, or processing conditions result in the morphology with the highest charge transport.
    \item {\textbf{Understand the mapping operator}}
        This work will test whether using a chemical string format (SMARTS/SMILES) to specify the atomistic to coarse-grained site mapping is a viable alternative to other methods. 
        Using SMARTS/SMILES strings allows a user to more easily and intuitively specify a mapping.
        If specifying a mapping is easier, a user may be more willing to try out a greater number of different mappings.
        This would allow for the comparison of a system parameterized with different mapping operators.
    \item {\textbf{Benefits of Transferrable, Reproducible, Usable, Extensible research}} %%what am i trying to say here?
        Does making science easier/more understandable make it better? %more reproducible? curb cuts
        If parameterizing a coarse-grained force field is easier and more approachable, it would open up more possibilities for trying different mapping schemes or different structural or thermodynamic targets rather than sticking to an existing force field.
        Better coarse-grained models could result in more accurate and efficient simulation of large length scale systems.
\end{enumerate}

\section*{Contingency Analysis}

Although minimum working examples have been developed for both the coarse-graining and backmapping packages, I still expect to struggle when mapping new compounds.
Sometimes the SMARTS/SMILES mapping won't work without careful choice of sites.
This can be a little frustrating but is still preferrable to having to manually specify the mapping of each atom.
At least the reasons that a SMARTS mapping fails are usually understandable (e.g., the order of the sites matters) or chemically sensible (e.g., one SMILES string may contain another --- just as one chemical moeity may be composed of more submoeities). %%<this is a word?>)

It may also be difficult to find a good coarse-graining scheme for the NFA compounds. 
These compounds are often composed of large planar backbones with floppy side chains.
Finding a suitable mapping to represent both aspects may be difficult.

\section*{Timeline for Implementation and Evaluation}
\begin{table}[h]
    \resizebox{\columnwidth}{!}{\renewcommand{\arraystretch}{1.1}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
        \multirow{2}{*}{PROJECT TASK}
            &\multicolumn{4}{c}{YEAR 1}
            &\multicolumn{4}{|c}{YEAR 2} 
            &\multicolumn{4}{|c}{YEAR 3} 
            &\multicolumn{4}{|c|}{YEAR 4} 
            &\multicolumn{4}{c|}{YEAR 5} \\ 
        \hhline{~--------------------}
        & 1 & 2 & 3 & 4 & 1 & 2 & 3 & 4 & 1 & 2 & 3 & 4 & 1 & 2 & 3 & 4 & 1 & 2 & 3 & 4\\
        \hline
        Complete Coursework 
            &\multicolumn{10}{|c|}{{\cellcolor{lgray}}} &  &  &  &  &  &  &  &  &  &\\
        \hline
        Present at a Conference  
            & & & & & & & & & & & x & & & & & & & & &\\
        \hline
        Publish a First Author Paper
            & & & & & & x & & & & & & & & & & & & & &\\
        \hline
        Proposal and Comprehensive Exam
            & & & & & & & & & & & & * & & & & & & & &\\
        \hline
        Expand Functionality of Open Source Packages 
            & & & & & & \multicolumn{11}{|c|}{{\cellcolor{lgray}}} & & & &\\
        \hline
        Develop Coarse Graining Package              
            & & & & & & & & & \multicolumn{8}{|c|}{{\cellcolor{lgray}}} & & & &\\
        \hline
        Develop Automated MS-IBI Code                
            & & & & & & & & & \multicolumn{8}{|c|}{{\cellcolor{lgray}}} & & & &\\
        \hline
        Develop Backmapping Package                  
            & & & & & & & & & & & & \multicolumn{5}{|c|}{{\cellcolor{lgray}}}& & & &\\
        \hline
        Generate Coarse-Grain Morphologies           
            & & & & & & & & & & & & & & \multicolumn{4}{|c|}{{\cellcolor{lgray}}}& & &\\
        \hline
        Evaluate OPV Device Performance 
            & & & & & & & & & & & & & & \multicolumn{4}{|c|}{{\cellcolor{lgray}}} & & &\\
        \hline
        Write Dissertation 
            & & & & & & & & & & & & & & & &\multicolumn{3}{|c|}{{\cellcolor{lgray}}} & &\\
        \hline
        Present Dissertation Defense  
            & & & & & & & & & & & & & & & & & & {\cellcolor{lgray}} &  &\\
        \hline
         %Saved row template
         %&  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \end{tabular}
    }
    \caption{Anticipated timeline. * indicates right now, x indicates already accomplished.}
\end{table}
